{
  "title": {
    "text": "RFC 6820 - Address Resolution Problems in Large Data Center Networks",
    "ja": "RFC 6820 - 大規模データセンターネットワークにおける解像度の問題に対処"
  },
  "number": 6820,
  "created_at": "2019-10-31 09:17:19.689375+09:00",
  "updated_by": "",
  "contents": [
    {
      "indent": 0,
      "text": "Internet Engineering Task Force (IETF)                         T. Narten\nRequest for Comments: 6820                               IBM Corporation\nCategory: Informational                                         M. Karir\nISSN: 2070-1721                                       Merit Network Inc.\n                                                                  I. Foo\n                                                     Huawei Technologies\n                                                            January 2013",
      "raw": true
    },
    {
      "indent": 7,
      "text": "Address Resolution Problems in Large Data Center Networks",
      "raw": true
    },
    {
      "indent": 0,
      "text": "Abstract",
      "ja": "抽象"
    },
    {
      "indent": 3,
      "text": "This document examines address resolution issues related to the scaling of data centers with a very large number of hosts. The scope of this document is relatively narrow, focusing on address resolution (the Address Resolution Protocol (ARP) in IPv4 and Neighbor Discovery (ND) in IPv6) within a data center.",
      "ja": "この文書では、ホストの非常に多くのデータセンターのスケーリングに関連したアドレス解決の問題を検討します。この文書の範囲は、データセンター内のアドレス解決（IPv6ではIPv4および近隣探索にアドレス解決プロトコル（ARP）（ND））に着目し、比較的狭いです。"
    },
    {
      "indent": 0,
      "text": "Status of This Memo",
      "ja": "このメモのステータス"
    },
    {
      "indent": 3,
      "text": "This document is not an Internet Standards Track specification; it is published for informational purposes.",
      "ja": "このドキュメントはインターネット標準化過程仕様ではありません。それは、情報提供の目的のために公開されています。"
    },
    {
      "indent": 3,
      "text": "This document is a product of the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by the Internet Engineering Steering Group (IESG). Not all documents approved by the IESG are a candidate for any level of Internet Standard; see Section 2 of RFC 5741.",
      "ja": "このドキュメントはインターネットエンジニアリングタスクフォース（IETF）の製品です。これは、IETFコミュニティの総意を表しています。これは、公開レビューを受けており、インターネットエンジニアリング運営グループ（IESG）によって公表のために承認されています。 IESGによって承認されていないすべての文書がインターネットStandardのどんなレベルの候補です。 RFC 5741のセクション2を参照してください。"
    },
    {
      "indent": 3,
      "text": "Information about the current status of this document, any errata, and how to provide feedback on it may be obtained at http://www.rfc-editor.org/info/rfc6820.",
      "ja": "このドキュメントの現在の状態、任意の正誤表、そしてどのようにフィードバックを提供するための情報がhttp://www.rfc-editor.org/info/rfc6820で取得することができます。"
    },
    {
      "indent": 0,
      "text": "Copyright Notice",
      "ja": "著作権表示"
    },
    {
      "indent": 3,
      "text": "Copyright (c) 2013 IETF Trust and the persons identified as the document authors. All rights reserved.",
      "ja": "著作権（C）2013 IETF信託とドキュメントの作成者として特定の人物。全著作権所有。"
    },
    {
      "indent": 3,
      "text": "This document is subject to BCP 78 and the IETF Trust's Legal Provisions Relating to IETF Documents (http://trustee.ietf.org/license-info) in effect on the date of publication of this document. Please review these documents carefully, as they describe your rights and restrictions with respect to this document. Code Components extracted from this document must include Simplified BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the Simplified BSD License.",
      "ja": "この文書では、BCP 78と、この文書の発行日に有効なIETFドキュメント（http://trustee.ietf.org/license-info）に関連IETFトラストの法律の規定に従うものとします。彼らは、この文書に関してあなたの権利と制限を説明するように、慎重にこれらの文書を確認してください。コードコンポーネントは、トラスト法規定のセクションで説明4.eおよび簡体BSDライセンスで説明したように、保証なしで提供されているよう簡体BSDライセンスのテキストを含める必要があり、この文書から抽出されました。"
    },
    {
      "indent": 0,
      "text": "Table of Contents",
      "ja": "目次"
    },
    {
      "indent": 3,
      "text": "1. Introduction ....................................................3\n2. Terminology .....................................................3\n3. Background ......................................................4\n4. Address Resolution in IPv4 ......................................6\n5. Address Resolution in IPv6 ......................................7\n6. Generalized Data Center Design ..................................7\n   6.1. Access Layer ...............................................8\n   6.2. Aggregation Layer ..........................................8\n   6.3. Core .......................................................9\n   6.4. L3/L2 Topological Variations ...............................9\n        6.4.1. L3 to Access Switches ...............................9\n        6.4.2. L3 to Aggregation Switches ..........................9\n        6.4.3. L3 in the Core Only ................................10\n        6.4.4. Overlays ...........................................10\n   6.5. Factors That Affect Data Center Design ....................11\n        6.5.1. Traffic Patterns ...................................11\n        6.5.2. Virtualization .....................................11\n        6.5.3. Summary ............................................12\n7. Problem Itemization ............................................12\n   7.1. ARP Processing on Routers .................................12\n   7.2. IPv6 Neighbor Discovery ...................................14\n   7.3. MAC Address Table Size Limitations in Switches ............15\n8. Summary ........................................................15\n9. Acknowledgments ................................................16\n10. Security Considerations .......................................16\n11. Informative References ........................................16",
      "raw": true
    },
    {
      "indent": 0,
      "text": "1. Introduction",
      "section_title": true,
      "ja": "1. はじめに"
    },
    {
      "indent": 3,
      "text": "This document examines issues related to the scaling of large data centers. Specifically, this document focuses on address resolution (ARP in IPv4 and Neighbor Discovery in IPv6) within the data center. Although strictly speaking the scope of address resolution is confined to a single L2 broadcast domain (i.e., ARP runs at the L2 layer below IP), the issue is complicated by routers having many interfaces on which address resolution must be performed or with the presence of IEEE 802.1Q domains, where individual VLANs effectively form their own L2 broadcast domains. Thus, the scope of address resolution spans both the L2 link and the devices attached to those links.",
      "ja": "このドキュメントでは、大規模データセンターのスケーリングに関連する問題を検討します。具体的には、この文書は、データセンター内のアドレス解決（IPv4のARPおよびIPv6における近隣探索）に焦点を当てています。厳密がアドレス解決の範囲（すなわち、ARPはIP以下L2層で動作）は、単一のL2ブロードキャストドメインに限定されて、問題がアドレス解決を実行する必要がある上に、多くのインターフェースを有するルータによってまたはの存在に複雑です個々のVLANが効果的に自分のL2ブロードキャストドメインを形成IEEE 802.1Qドメイン、。これにより、アドレス解決の範囲はL2リンクおよびこれらのリンクに接続されているデバイスの両方にまたがっています。"
    },
    {
      "indent": 3,
      "text": "This document identifies potential issues associated with address resolution in data centers with a large number of hosts. The scope of this document is intentionally relatively narrow, as it mirrors the Address Resolution for Massive numbers of hosts in the Data center (ARMD) WG charter. This document lists \"pain points\" that are being experienced in current data centers. The goal of this document is to focus on address resolution issues and not other broader issues that might arise in data centers.",
      "ja": "この文書では、ホストの数が多いデータセンター内のアドレス解決に関連した潜在的な問題を識別する。それはデータセンター内のホストの膨大な数のためのアドレス解決（ARMD）WGチャーターをミラーとして、この文書の範囲は、意図的に比較的狭いです。現在のデータセンターで経験されている。この文書リスト「痛点」。このドキュメントの目標は、アドレス解決の問題ではなく、データセンターで発生する可能性がある他のより広範な問題に集中することです。"
    },
    {
      "indent": 0,
      "text": "2. Terminology",
      "section_title": true,
      "ja": "2.用語"
    },
    {
      "indent": 3,
      "text": "Address Resolution: The process of determining the link-layer address corresponding to a given IP address. In IPv4, address resolution is performed by ARP [RFC0826]; in IPv6, it is provided by Neighbor Discovery (ND) [RFC4861].",
      "ja": "アドレス解決：特定のIPアドレスに対応するリンク層アドレスを決定するプロセス。 IPv4では、アドレス解決は、ARP [RFC0826]によって行われます。 IPv6では、それは近隣探索（ND）[RFC4861]によって与えられます。"
    },
    {
      "indent": 3,
      "text": "Application: Software that runs on either a physical or virtual machine, providing a service (e.g., web server, database server, etc.).",
      "ja": "アプリケーション：サービスを提供する、物理または仮想マシンのいずれかで動作するソフトウェア（例えば、Webサーバ、データベースサーバなど）。"
    },
    {
      "indent": 3,
      "text": "L2 Broadcast Domain: The set of all links, repeaters, and switches that are traversed to reach all nodes that are members of a given L2 broadcast domain. In IEEE 802.1Q networks, a broadcast domain corresponds to a single VLAN.",
      "ja": "L2ブロードキャストドメイン：指定したL2ブロードキャストドメインのメンバであるすべてのノードに到達するために横断されているすべてのリンク、リピータ、およびスイッチのセット。 IEEE 802.1Qネットワークでは、ブロードキャストドメインは、単一のVLANに対応しています。"
    },
    {
      "indent": 3,
      "text": "Host (or server): A computer system on the network.",
      "ja": "ホスト（サーバー）：ネットワーク上のコンピュータシステム。"
    },
    {
      "indent": 3,
      "text": "Hypervisor: Software running on a host that allows multiple VMs to run on the same host.",
      "ja": "ハイパーバイザー：ソフトウェアの複数のVMが同じホスト上で実行することを可能にするホスト上で実行されています。"
    },
    {
      "indent": 3,
      "text": "Virtual Machine (VM): A software implementation of a physical machine that runs programs as if they were executing on a physical, non-virtualized machine. Applications (generally) do not know they are running on a VM as opposed to running on a",
      "ja": "仮想マシン（VM）：彼らは物理的、非仮想化マシン上で実行しているかのようプログラムを実行している物理マシンのソフトウェア実装。上で実行されているとは対照的に、アプリケーションは、（一般的に）彼らはVM上で実行されているかわかりません"
    },
    {
      "indent": 6,
      "text": "\"bare\" host or server, though some systems provide a paravirtualization environment that allows an operating system or application to be aware of the presence of virtualization for optimization purposes.",
      "ja": "「裸の」ホストまたはサーバ、いくつかのシステムでは、オペレーティングシステムやアプリケーションが最適化のための仮想化の存在を認識することを可能にする準仮想化環境を提供するけれども。"
    },
    {
      "indent": 3,
      "text": "ToR: Top-of-Rack Switch. A switch placed in a single rack to aggregate network connectivity to and from hosts in that rack.",
      "ja": "ToR：トップ・オブ・ラックスイッチ。単一のラックに配置されたスイッチに、そのラック内のホストからのネットワーク接続を集約します。"
    },
    {
      "indent": 3,
      "text": "EoR: End-of-Row Switch. A switch used to aggregate network connectivity from multiple racks. EoR switches are the next level of switching above ToR switches.",
      "ja": "EOR：エンド・オブ・ロウのスイッチ。複数のラックからのネットワーク接続を集約するために使用されるスイッチ。 EORスイッチはのToRスイッチの上方に切り替え、次のレベルです。"
    },
    {
      "indent": 0,
      "text": "3. Background",
      "section_title": true,
      "ja": "3.背景"
    },
    {
      "indent": 3,
      "text": "Large, flat L2 networks have long been known to have scaling problems. As the size of an L2 broadcast domain increases, the level of broadcast traffic from protocols like ARP increases. Large amounts of broadcast traffic pose a particular burden because every device (switch, host, and router) must process and possibly act on such traffic. In extreme cases, \"broadcast storms\" can occur where the quantity of broadcast traffic reaches a level that effectively brings down part or all of a network. For example, poor implementations of loop detection and prevention or misconfiguration errors can create conditions that lead to broadcast storms as network conditions change. The conventional wisdom for addressing such problems has been to say \"don't do that\". That is, split large L2 networks into multiple smaller L2 networks, each operating as its own L3/IP subnet. Numerous data center networks have been designed with this principle, e.g., with each rack placed within its own L3 IP subnet. By doing so, the broadcast domain (and address resolution) is confined to one ToR switch, which works well from a scaling perspective. Unfortunately, this conflicts in some ways with the current trend towards dynamic workload shifting in data centers and increased virtualization, as discussed below.",
      "ja": "大規模な、フラットなL2ネットワークが長い問題をスケーリングしていることが知られています。 L2ブロードキャストドメインのサイズが大きく、ARP増加などのプロトコルからのブロードキャストトラフィックのレベルとして。すべてのデバイス（スイッチ、ホスト、およびルータ）が処理し、おそらくそのようなトラフィックに基づいて行動しなければならないため、ブロードキャストトラフィックの大量のは、特定負担をもたらします。ブロードキャストトラフィックの量を効果的に一部またはネットワークのすべてをダウンさせるレベルに達した場合、極端な場合には、「ブロードキャストストーム」が起こることができます。例えば、ループ検出および防止または設定ミスエラーの貧弱な実装は、ネットワーク状態の変化としてストームを放送するために導く条件を作成することができます。このような問題に対処するため、従来の知恵は「それをしない」と言ってきました。すなわち、各独自のL3 / IPサブネットとして動作し、複数の小さなL2ネットワークに大きなL2ネットワークを分割する、です。各ラックは、それ自身のL3 IPサブネット内に配置して多数のデータセンターネットワークは、例えば、この原理を用いて設計されています。そうすることによって、ブロードキャストドメイン（アドレス解決）は、スケーリングの観点からうまく機能1つのToRスイッチに限定されています。残念ながら、後述するように、動的ワークロードに向かって現在の傾向は、データセンターおよび増加仮想化シフトといくつかの方法でこの競合。"
    },
    {
      "indent": 3,
      "text": "Workload placement has become a challenging task within data centers. Ideally, it is desirable to be able to dynamically reassign workloads within a data center in order to optimize server utilization, add more servers in response to increased demand, etc. However, servers are often pre-configured to run with a given set of IP addresses. Placement of such servers is then subject to constraints of the IP addressing restrictions of the data center. For example, servers configured with addresses from a particular subnet could only be placed where they connect to the IP subnet corresponding to their IP addresses. If each ToR switch is acting as a gateway for its own subnet, a server can only be connected to the one ToR switch. This gateway switch represents the L2/L3 boundary. A similar constraint occurs in virtualized environments, as discussed next.",
      "ja": "ワークロードの配置は、データセンター内の困難な作業となっています。理想的には、動的に、サーバーの使用率を最適化するために、データセンター内のワークロードを再割り当てなどの需要増に対応し、しかし、サーバは、多くの場合、IPの特定のセットで実行するように事前に構成されている中でより多くのサーバーを追加することができるようにすることが望ましいですアドレス。そのようなサーバの配置は、データセンターの制限をIPアドレス指定の制約を受けています。彼らは自分のIPアドレスに対応するIPサブネットに接続する場所たとえば、特定のサブネットからのアドレスを使用して設定されたサーバにのみ配置することができます。それぞれのToRスイッチは、自身のサブネットのゲートウェイとして機能している場合、サーバは、ただ1つのToRスイッチに接続することができます。このゲートウェイスイッチは、L2 / L3境界を表します。次の議論と同様の制約は、仮想化環境で起こります。"
    },
    {
      "indent": 3,
      "text": "Server virtualization is fast becoming the norm in data centers. With server virtualization, each physical server supports multiple virtual machines, each running its own operating system, middleware, and applications. Virtualization is a key enabler of workload agility, i.e., allowing any server to host any application (on its own VM) and providing the flexibility of adding, shrinking, or moving VMs within the physical infrastructure. Server virtualization provides numerous benefits, including higher utilization, increased data security, reduced user downtime, and even significant power conservation, along with the promise of a more flexible and dynamic computing environment.",
      "ja": "サーバ仮想化は、高速なデータセンターで当たり前になってきています。サーバ仮想化では、各物理サーバは、それぞれが独自のオペレーティングシステム、ミドルウェア、およびアプリケーションを実行し、複数の仮想マシンをサポートしています。仮想化は、すなわち、いずれかのサーバが（独自のVM上の）任意のアプリケーションをホストすることを可能にすると、追加収縮、または物理的なインフラストラクチャ内のVMを移動させる柔軟性を提供し、ワークロードアジリティのキーイネーブラです。サーバ仮想化は、より柔軟でダイナミックなコンピューティング環境の約束とともに、高い利用率、増加データセキュリティ、縮小ユーザーのダウンタイム、さらに大幅な省電力化など、さまざまな利点を提供します。"
    },
    {
      "indent": 3,
      "text": "The discussion below focuses on VM placement and migration. Keep in mind, however, that even in a non-virtualized environment, many of the same issues apply to individual workloads running on standalone machines. For example, when increasing the number of servers running a particular workload to meet demand, placement of those workloads may be constrained by IP subnet numbering considerations, as discussed earlier.",
      "ja": "以下の議論は、VMの配置と移行に焦点を当てています。でも、非仮想化環境では、同じ問題の多くは、スタンドアロンのマシン上で実行されている個々のワークロードに適用されていること、しかし、覚えておいてください。需要を満たすために、特定のワークロードを実行しているサーバーの数を増やすときに前述したように、例えば、これらのワークロードの配置は、IPサブネット番号の考慮によって制約されてもよいです。"
    },
    {
      "indent": 3,
      "text": "The greatest flexibility in VM and workload management occurs when it is possible to place a VM (or workload) anywhere in the data center regardless of what IP addresses the VM uses and how the physical network is laid out. In practice, movement of VMs within a data center is easiest when VM placement and movement do not conflict with the IP subnet boundaries of the data center's network, so that the VM's IP address need not be changed to reflect its actual point of attachment on the network from an L3/IP perspective. In contrast, if a VM moves to a new IP subnet, its address must change, and clients will need to be made aware of that change. From a VM management perspective, management is simplified if all servers are on a single large L2 network.",
      "ja": "関係なく、VMを使用し、物理的なネットワークがどのようにレイアウトされているものIPアドレスがどこかのデータセンター内のVM（またはワークロード）を配置することが可能であるとき、VMとワークロード管理の最大の柔軟性が起こります。 VMのIPアドレスが、上の添付ファイルの実際の位置を反映するように変更する必要はありませんように、VMの配置や動きは、データセンターのネットワークのIPサブネットの境界と競合しないとき実際には、データセンター内の仮想マシンの動きが最も簡単ですL3 / IPの観点からネットワーク。 VMは、新しいIPサブネットに移動するとは対照的に、そのアドレスを変更しなければならない、とクライアントがその変更を知らされる必要があります。すべてのサーバーが単一の大規模なL2ネットワーク上にある場合、VM管理の観点から、管理が簡素化されます。"
    },
    {
      "indent": 3,
      "text": "With virtualization, it is not uncommon to have a single physical server host ten or more VMs, each having its own IP (and Media Access Control (MAC)) addresses. Consequently, the number of addresses per machine (and hence per subnet) is increasing, even when the number of physical machines stays constant. In a few years, the numbers will likely be even higher.",
      "ja": "仮想化では、単一の物理サーバのホスト10台の以上のVM、それぞれが独自のIP（およびメディアアクセス制御（MAC））はアドレスを持つことは珍しいことではありません。したがって、アドレスの数は、マシンごとに（したがって、サブネットごとに）物理マシンの数は一定のままであっても、増加しています。数年では、数字はおそらくさらに高くなります。"
    },
    {
      "indent": 3,
      "text": "In the past, applications were static in the sense that they tended to stay in one physical place. An application installed on a physical machine would stay on that machine because the cost of moving an application elsewhere was generally high. Moreover, physical servers hosting applications would tend to be placed in such a way as to facilitate communication locality. That is, applications running on servers would be physically located near the servers hosting the applications they communicated with most heavily. The network traffic patterns in such environments could thus be optimized, in some cases keeping significant traffic local to one network segment. In these more static and carefully managed environments, it was possible to build networks that approached scaling limitations but did not actually cross the threshold.",
      "ja": "過去には、アプリケーションは1つの物理場所に滞在する傾向が見られたという意味では静的でした。他の場所でアプリケーションを移動するコストは、一般的に高いため、物理マシン上にインストールされたアプリケーションは、そのマシンにとどまります。また、アプリケーションをホストする物理サーバーは、通信の局所性を容易にするように配置される傾向にあるだろう。これは、サーバ上で実行されるアプリケーションは、物理的に、彼らは最も頻繁に通信するアプリケーションをホスティングしているサーバの近くに配置されることになる、です。このような環境でネットワークトラフィックパターンは、このように一つのネットワークセグメントにローカル重要トラフィックを維持するいくつかのケースでは、最適化することができます。これらのより静的かつ慎重に管理された環境では、スケーリングの限界に近づいたが、実際には、閾値を越えていなかったネットワークを構築することが可能でした。"
    },
    {
      "indent": 3,
      "text": "Today, with the proliferation of VMs, traffic patterns are becoming more diverse and less predictable. In particular, there can easily be less locality of network traffic as VMs hosting applications are moved for such reasons as reducing overall power usage (by consolidating VMs and powering off idle machines) or moving a VM to a physical server with more capacity or a lower load. In today's changing environments, it is becoming more difficult to engineer networks as traffic patterns continually shift as VMs move around.",
      "ja": "今日では、VMの増殖に、トラフィックパターンはより多様で予測しにくいになっています。 VMをホストしているアプリケーションは、（VMを統合し、アイドル状態マシンの電源をオフにすることによって）、全体的な電力使用を低減またはより多くの容量以下と物理サーバにVMを移動するなどの理由で移動されるように、特に、容易にネットワークトラフィックの少ない地域が存在することができます負荷。今日の変化する環境では、VMが動き回るようなトラフィックパターンが継続的にシフトするようなネットワークを設計することはより困難になってきています。"
    },
    {
      "indent": 3,
      "text": "In summary, both the size and density of L2 networks are increasing. In addition, increasingly dynamic workloads and the increased usage of VMs are creating pressure for ever-larger L2 networks. Today, there are already data centers with over 100,000 physical machines and many times that number of VMs. This number will only increase going forward. In addition, traffic patterns within a data center are also constantly changing. Ultimately, the issues described in this document might be observed at any scale, depending on the particular design of the data center.",
      "ja": "要約すると、L2ネットワークのサイズ及び密度の両方が増加しています。加えて、ますます動的ワークロードとVMの増加利用はますます大きなL2ネットワークの圧力を作成します。今日、10万人以上の物理マシンと何度もVMのその番号のデータセンターでは、すでに存在しています。この番号は、今後増加するであろう。また、データセンター内のトラフィックパターンも常に変化しています。最終的には、この文書で説明する問題は、データセンターの特定の設計に応じて、任意のスケールで観察される可能性があります。"
    },
    {
      "indent": 0,
      "text": "4. Address Resolution in IPv4",
      "section_title": true,
      "ja": "IPv4の4.アドレス解決"
    },
    {
      "indent": 3,
      "text": "In IPv4 over Ethernet, ARP provides the function of address resolution. To determine the link-layer address of a given IP address, a node broadcasts an ARP Request. The request is delivered to all portions of the L2 network, and the node with the requested IP address responds with an ARP Reply. ARP is an old protocol and, by current standards, is sparsely documented. For example, there are no clear requirements for retransmitting ARP Requests in the absence of replies. Consequently, implementations vary in the details of what they actually implement [RFC0826][RFC1122].",
      "ja": "イーサネット上のIPv4では、ARPは、アドレス解決の機能を提供します。与えられたIPアドレスのリンク層アドレスを決定するには、ノードは、ARP要求をブロードキャストします。要求は、L2ネットワークの全ての部分に送達され、要求されたIPアドレスを持つノードは、ARP応答で応答します。 ARPは古いプロトコルであり、現在の基準で、まばらに文書化されています。たとえば、返答がない場合にARP要求を再送信するための明確な要件はありません。したがって、実装は、それらが実際に[RFC0826]、[RFC1122]を実装することの詳細が異なります。"
    },
    {
      "indent": 3,
      "text": "From a scaling perspective, there are a number of problems with ARP. First, it uses broadcast, and any network with a large number of attached hosts will see a correspondingly large amount of broadcast ARP traffic. The second problem is that it is not feasible to change host implementations of ARP -- current implementations are too widely entrenched, and any changes to host implementations of ARP would take years to become sufficiently deployed to matter. That said, it may be possible to change ARP implementations in hypervisors, L2/L3 boundary routers, and/or ToR access switches, to leverage such techniques as Proxy ARP. Finally, ARP implementations need to take steps to flush out stale or otherwise invalid entries.",
      "ja": "スケーリングの観点から、ARPの問題点がいくつかあります。まず、それはブロードキャストを使用し、接続されたホストの数が多いと、任意のネットワークは、ブロードキャストARPトラフィックの対応する大き​​な金額が表示されます。第二の問題は、ARPのホストの実装を変更することは不可能であるということです - 現在の実装では、あまりにも広く定着している、とARPの実装をホストするすべての変更は、十分には関係する展開になるために何年もかかるでしょう。つまり、プロキシARPなどの技術を活用し、ハイパーバイザ、L2 / L3境界ルータ、及び/又はのToRアクセススイッチでARPの実装を変更することが可能である、と述べました。最後に、ARPの実装は古いまたはその他の無効なエントリをフラッシュするための措置をとる必要があります。"
    },
    {
      "indent": 3,
      "text": "Unfortunately, existing standards do not provide clear implementation guidelines for how to do this. Consequently, implementations vary significantly, and some implementations are \"chatty\" in that they just periodically flush caches every few minutes and send new ARP queries.",
      "ja": "残念ながら、既存の標準は、これを行う方法のための明確な実装ガイドラインを提供していません。その結果、実装は大幅に変化し、いくつかの実装は、彼らだけで定期的にフラッシュキャッシュに数分おきに「おしゃべり」であり、新しいARPクエリを送信します。"
    },
    {
      "indent": 0,
      "text": "5. Address Resolution in IPv6",
      "section_title": true,
      "ja": "IPv6での5アドレス解決"
    },
    {
      "indent": 3,
      "text": "Broadly speaking, from the perspective of address resolution, IPv6's Neighbor Discovery (ND) behaves much like ARP, with a few notable differences. First, ARP uses broadcast, whereas ND uses multicast. When querying for a target IP address, ND maps the target address into an IPv6 Solicited Node multicast address. Using multicast rather than broadcast has the benefit that the multicast frames do not necessarily need to be sent to all parts of the network, i.e., the frames can be sent only to segments where listeners for the Solicited Node multicast address reside. In the case where multicast frames are delivered to all parts of the network, sending to a multicast address still has the advantage that most (if not all) nodes will filter out the (unwanted) multicast query via filters installed in the Network Interface Card (NIC) rather than burdening host software with the need to process such packets. Thus, whereas all nodes must process every ARP query, ND queries are processed only by the nodes to which they are intended. In cases where multicast filtering can't effectively be implemented in the NIC (e.g., as on hypervisors supporting virtualization), filtering would need to be done in software (e.g., in the hypervisor's vSwitch).",
      "ja": "大まかにアドレス解決の観点から言えば、IPv6のの近隣探索（ND）は、いくつかの顕著な違いで、多くのARPのように振る舞います。 NDは、マルチキャストを使用し、一方、第一に、ARPは、ブロードキャストを使用しています。ターゲットIPアドレスを照会すると、NDは、IPv6要請ノードマルチキャストアドレスにターゲットアドレスをマッピングします。マルチキャストではなくブロードキャストを使用してマルチキャストフレームは、必ずしもネットワークのすべての部分に送信する必要がないという利点を有し、すなわち、フレームは、要請ノードマルチキャストアドレスのリスナーが存在するセグメントに送信することができます。マルチキャストフレームはネットワークのすべての部分に配信されている場合には、マルチキャストアドレスに送信することはまだほとんど（すべてではない）のノードが（ネットワーク・インタフェース・カードにインストールされているフィルタを経由して（不要）マルチキャストクエリーを除外します利点を持っていますNIC）のではなく、そのようなパケットを処理する必要性をホストソフトウェアに負担をかけます。すべてのノードがすべてのARPクエリを処理しなければならないのに対し、このように、NDクエリは、彼らだけが意図されているために、ノードによって処理されています。 （例えば、仮想化をサポートするハイパーバイザー上など）マルチキャストフィルタリングが有効NICに実装することができない場合には、フィルタリングは、（例えば、ハイパーバイザのvSwitchに）ソフトウェアで実行される必要があるであろう。"
    },
    {
      "indent": 0,
      "text": "6. Generalized Data Center Design",
      "section_title": true,
      "ja": "6.一般データセンター設計"
    },
    {
      "indent": 3,
      "text": "There are many different ways in which data center networks might be designed. The designs are usually engineered to suit the particular workloads that are being deployed in the data center. For example, a large web server farm might be engineered in a very different way than a general-purpose multi-tenant cloud hosting service. However, in most cases the designs can be abstracted into a typical three-layer model consisting of an access layer, an aggregation layer, and the Core. The access layer generally refers to the switches that are closest to the physical or virtual servers; the aggregation layer serves to interconnect multiple access-layer devices. The Core switches connect the aggregation switches to the larger network core.",
      "ja": "データセンターネットワークを設計する可能性のある多くの異なる方法があります。デザインは、通常、データセンターに展開されている特定のワークロードに合わせて設計されています。たとえば、大規模なWebサーバーファームは、汎用マルチテナントクラウドホスティングサービスとは非常に異なる方法で設計されることがあります。しかし、ほとんどの場合、設計は、アクセスレイヤ、アグリゲーション層、及びコアからなる典型的な3層モデルに抽象化することができます。アクセス層は、一般に、物理的または仮想サーバに最も近いスイッチを指します。アグリゲーション層は、複数のアクセスレイヤデバイスを相互接続するのに役立ちます。コアは、より大きなネットワークのコアに集約スイッチを接続するスイッチ。"
    },
    {
      "indent": 3,
      "text": "Figure 1 shows a generalized data center design, which captures the essential elements of various alternatives.",
      "ja": "図1は、様々な代替の必須要素を捕捉する一般的なデータセンターの設計を示しています。"
    },
    {
      "indent": 17,
      "text": " +-----+-----+     +-----+-----+\n |   Core0   |     |    Core1  |      Core\n +-----+-----+     +-----+-----+\n       /    \\        /       /\n      /      \\----------\\   /\n     /    /---------/    \\ /\n   +-------+           +------+\n +/------+ |         +/-----+ |\n | Aggr11| + --------|AggrN1| +      Aggregation Layer\n +---+---+/          +------+/\n   /     \\            /      \\\n  /       \\          /        \\\n+---+    +---+      +---+     +---+\n|T11|... |T1x|      |TN1|     |TNy|  Access Layer\n+---+    +---+      +---+     +---+\n|   |    |   |      |   |     |   |\n+---+    +---+      +---+     +---+\n|   |... |   |      |   |     |   |\n+---+    +---+      +---+     +---+  Server Racks\n|   |... |   |      |   |     |   |\n+---+    +---+      +---+     +---+\n|   |... |   |      |   |     |   |\n+---+    +---+      +---+     +---+",
      "raw": true
    },
    {
      "indent": 15,
      "text": "Typical Layered Architecture in a Data Center",
      "ja": "データセンターでの典型的な階層化アーキテクチャ"
    },
    {
      "indent": 33,
      "text": "Figure 1",
      "ja": "図1"
    },
    {
      "indent": 0,
      "text": "6.1. Access Layer",
      "section_title": true,
      "ja": "6.1. アクセスレイヤ"
    },
    {
      "indent": 3,
      "text": "The access switches provide connectivity directly to/from physical and virtual servers. The access layer may be implemented by wiring the servers within a rack to a ToR switch or, less commonly, the servers could be wired directly to an EoR switch. A server rack may have a single uplink to one access switch or may have dual uplinks to two different access switches.",
      "ja": "アクセススイッチは、物理サーバーと仮想サーバーから/への直接接続を提供します。アクセス層のToRスイッチや、あまり一般的で、サーバーはEORスイッチに直接接続することができ、ラック内のサーバーを配線することによって実現されてもよいです。サーバラックは、一つのアクセススイッチに単一のアップリンクを有していてもよくまたは2つの異なるアクセススイッチに二重のアップリンクを有することができます。"
    },
    {
      "indent": 0,
      "text": "6.2. Aggregation Layer",
      "section_title": true,
      "ja": "6.2. アグリゲーションレイヤ"
    },
    {
      "indent": 3,
      "text": "In a typical data center, aggregation switches interconnect many ToR switches. Usually, there are multiple parallel aggregation switches, serving the same group of ToRs to achieve load sharing. It is no longer uncommon to see aggregation switches interconnecting hundreds of ToR switches in large data centers.",
      "ja": "典型的なデータセンターでは、集合は、相互接続多くのToRスイッチを切り替えます。通常、負荷分散を達成するために、TORSの同じグループにサービスを提供する複数の並列集約スイッチがあります。 Torは大規模なデータセンター内のスイッチのアグリゲーションスイッチは、何百もの相互参照することはもはや珍しいことではありません。"
    },
    {
      "indent": 0,
      "text": "6.3. Core",
      "section_title": true,
      "ja": "6.3. コア"
    },
    {
      "indent": 3,
      "text": "Core switches provide connectivity between aggregation switches and the main data center network. Core switches interconnect different sets of racks and provide connectivity to data center gateways leading to external networks.",
      "ja": "コアスイッチは、集約スイッチとメインデータセンターネットワーク間の接続を提供します。コアは、ラックの配線異なるセットを切り替え、外部のネットワークにつながるデータセンターのゲートウェイへの接続を提供します。"
    },
    {
      "indent": 0,
      "text": "6.4. L3/L2 Topological Variations",
      "section_title": true,
      "ja": "6.4.  L3 / L2トポロジーバリエーション"
    },
    {
      "indent": 0,
      "text": "6.4.1. L3 to Access Switches",
      "section_title": true,
      "ja": "6.4.1. アクセススイッチにL3"
    },
    {
      "indent": 3,
      "text": "In this scenario, the L3 domain is extended all the way from the core network to the access switches. Each rack enclosure consists of a single L2 domain, which is confined to the rack. In general, there are no significant ARP/ND scaling issues in this scenario, as the L2 domain cannot grow very large. Such a topology has benefits in scenarios where servers attached to a particular access switch generally run VMs that are confined to using a single subnet. These VMs and the applications they host aren't moved (migrated) to other racks that might be attached to different access switches (and different IP subnets). A small server farm or very static compute cluster might be well served via this design.",
      "ja": "このシナリオでは、L3ドメインは、アクセススイッチにコアネットワークからのすべての方法を拡張しています。各ラックエンクロージャは、ラックに限定される単一のL2ドメインからなります。 L2ドメインが非常に大きくなることができないとして、一般的には、有意なARP / NDのスケーリングの問題は、このシナリオではありません。このようなトポロジは、特定のアクセススイッチに接続されたサーバは、一般的に単一のサブネットを使用に限定されているVMを実行するシナリオでの利点があります。これらのVMやアプリケーション、彼らはホストが異なるアクセス・スイッチ（および異なるIPサブネット）に接続されるかもしれない他のラックに（移行）に移動されていません。小規模なサーバーファームまたは非常に静的な計算クラスタはよくこのデザインを経由して提供される可能性があります。"
    },
    {
      "indent": 0,
      "text": "6.4.2. L3 to Aggregation Switches",
      "section_title": true,
      "ja": "6.4.2. アグリゲーションスイッチへのL3"
    },
    {
      "indent": 3,
      "text": "When the L3 domain extends only to aggregation switches, hosts in any of the IP subnets configured on the aggregation switches can be reachable via L2 through any access switches if access switches enable all the VLANs. Such a topology allows a greater level of flexibility, as servers attached to any access switch can run any VMs that have been provisioned with IP addresses configured on the aggregation switches. In such an environment, VMs can migrate between racks without IP address changes. The drawback of this design, however, is that multiple VLANs have to be enabled on all access switches and all access-facing ports on aggregation switches. Even though L2 traffic is still partitioned by VLANs, the fact that all VLANs are enabled on all ports can lead to broadcast traffic on all VLANs that traverse all links and ports, which has the same effect as one big L2 domain on the access-facing side of the aggregation switch. In addition, the internal traffic itself might have to cross different L2 boundaries, resulting in significant ARP/ND load at the aggregation switches. This design provides a good tradeoff between flexibility and L2 domain size. A moderate-sized data center might utilize this approach to provide high-availability services at a single location.",
      "ja": "L3ドメインが集約スイッチにのみ延びている場合、アクセススイッチは、すべてのVLANを有効にする場合、集約スイッチに設定されたIPサブネットの任意のホストは、任意のアクセススイッチを介してL2を介して到達可能であることができます。任意のアクセススイッチに接続されているサーバは、集約スイッチに設定されたIPアドレスがプロビジョニングされたすべての仮想マシンを実行することができるように、そのようなトポロジーは、柔軟性の高いレベルを可能にします。このような環境では、VMはIPアドレスを変更することなく、ラック間を移動することができます。この設計の欠点は、しかし、複数のVLANがすべてのアクセススイッチと集約スイッチ上のすべてのアクセスに面したポート上で有効にしなければならないことです。 L2トラフィックがまだのVLANで仕切られていても、すべてのVLANはすべてのポートで有効になっているという事実は、アクセス向きで一つの大きなL2ドメインと同じ効果を持つ、すべてのリンクとのポートを通過するすべてのVLAN上のトラフィックをブロードキャストにつながることができますアグリゲーションスイッチの側面。加えて、内部トラフィック自体は、集約スイッチで有意ARP / ND負荷をもたらす、異なるL2の境界を横断する必要があるかもしれません。この設計は、柔軟性とL2ドメインサイズとの間に良好なトレードオフを提供します。中規模のデータセンターは、単一の場所での高可用性サービスを提供するために、このアプローチを利用することがあります。"
    },
    {
      "indent": 0,
      "text": "6.4.3. L3 in the Core Only",
      "section_title": true,
      "ja": "6.4.3. コアだけでL3"
    },
    {
      "indent": 3,
      "text": "In some cases, where a wider range of VM mobility is desired (i.e., a greater number of racks among which VMs can move without IP address changes), the L3 routed domain might be terminated at the core routers themselves. In this case, VLANs can span multiple groups of aggregation switches, which allows hosts to be moved among a greater number of server racks without IP address changes. This scenario results in the largest ARP/ND performance impact, as explained later. A data center with very rapid workload shifting may consider this kind of design.",
      "ja": "VMの移動度の広い範囲が所望されるいくつかの場合、（VMはIPアドレスを変更することなく移動することができ、その中のラック、すなわち、より多数）において、L3は、ドメインは、コアルータ自体で終端されるかもしれないルーティングされます。この場合、VLANは、ホストがIPアドレスの変更せずにサーバラックのより多くの間で移動することを可能にする集約スイッチ、複数のグループにまたがることができます。後述するように、このシナリオでは、最大のARP / NDのパフォーマンスへの影響につながります。非常に迅速なワークロードの移行とデータセンターは、この種の設計を考慮することができます。"
    },
    {
      "indent": 0,
      "text": "6.4.4. Overlays",
      "section_title": true,
      "ja": "6.4.4. オーバーレイ"
    },
    {
      "indent": 3,
      "text": "There are several approaches where overlay networks can be used to build very large L2 networks to enable VM mobility. Overlay networks using various L2 or L3 mechanisms allow interior switches/routers to mask host addresses. In addition, L3 overlays can help the data center designer control the size of the L2 domain and also enhance the ability to provide multi-tenancy in data center networks. However, the use of overlays does not eliminate traffic associated with address resolution; it simply moves it to regular data traffic. That is, address resolution is implemented in the overlay and is not directly visible to the switches of the data center network.",
      "ja": "オーバーレイネットワークは、VMの移動を可能にするために、非常に大規模なL2ネットワークを構築するために使用できるいくつかの方法があります。種々のL2またはL3メカニズムを使用してオーバーレイネットワークは、内部スイッチ/ルータは、ホストアドレスをマスクすることを可能にします。また、L3オーバーレイは、データセンターの設計者はL2ドメインのサイズを制御し、また、データセンタネットワークにおけるマルチテナントを提供する能力を強化することができます。しかし、オーバーレイを使用すると、アドレス解決に関連するトラフィックを排除しません。それは単に、通常のデータトラフィックに移動します。すなわち、アドレス解決は、オーバーレイで実装され、直接データセンターネットワークのスイッチには表示されませんされています。"
    },
    {
      "indent": 3,
      "text": "A potential problem that arises in a large data center is that when a large number of hosts communicate with their peers in different subnets, all these hosts send (and receive) data packets to their respective L2/L3 boundary nodes, as the traffic flows are generally bidirectional. This has the potential to further highlight any scaling problems. These L2/L3 boundary nodes have to process ARP/ND requests sent from originating subnets and resolve physical (MAC) addresses in the target subnets for what are generally bidirectional flows. Therefore, for maximum flexibility in managing the data center workload, it is often desirable to use overlays to place related groups of hosts in the same topological subnet to avoid the L2/L3 boundary translation. The use of overlays in the data center network can be a useful design mechanism to help manage a potential bottleneck at the L2/L3 boundary by redefining where that boundary exists.",
      "ja": "大規模なデータセンターに生じる潜在的な問題は、多数のホストが異なるサブネットにそのピアと通信するとき、トラフィックの流れがあるように、これらすべてのホストは、それらのそれぞれのL2 / L3境界ノードにデータパケットを送信（及び受信）することです一般的に双方向。これは、さらに任意のスケーリングの問題を強調する可能性を秘めています。これらのL2 / L3境界ノードは、発信元のサブネットから送信されたARP / ND要求を処理して、一般的に双方向の流れであるもののためにターゲットサブネット内の物理（MAC）アドレスを解決しなければなりません。そのため、データセンターのワークロードを管理する上で最大の柔軟性のために、L2 / L3境界の翻訳を避けるために、同じトポロジカルサブネット内のホストの関連グループを配置するためにオーバーレイを使用することが望ましいことが多いです。データセンターネットワークにおけるオーバーレイの使用は、その境界が存在する場合に再定義することでL2 / L3境界における潜在的なボトルネックを管理するための有用な設計機構とすることができます。"
    },
    {
      "indent": 0,
      "text": "6.5. Factors That Affect Data Center Design",
      "section_title": true,
      "ja": "6.5. データセンターの設計に影響を与える要因"
    },
    {
      "indent": 0,
      "text": "6.5.1. Traffic Patterns",
      "section_title": true,
      "ja": "6.5.1. トラフィックパターン"
    },
    {
      "indent": 3,
      "text": "Expected traffic patterns play an important role in designing appropriately sized access, aggregation, and core networks. Traffic patterns also vary based on the expected use of the data center.",
      "ja": "予想されるトラフィックパターンは、適切なサイズのアクセス、アグリゲーション、およびコアネットワークを設計する上で重要な役割を果たしています。トラフィックパターンは、データセンターの予想される使用に基づいて異なります。"
    },
    {
      "indent": 3,
      "text": "Broadly speaking, it is desirable to keep as much traffic as possible on the access layer in order to minimize the bandwidth usage at the aggregation layer. If the expected use of the data center is to serve as a large web server farm, where thousands of nodes are doing similar things and the traffic pattern is largely in and out of a large data center, an access layer with EoR switches might be used, as it minimizes complexity, allows for servers and databases to be located in the same L2 domain, and provides for maximum density.",
      "ja": "大まかに言えば、アグリゲーションレイヤでの帯域幅の使用を最小限にするために、アクセス層の上に、できるだけ多くのトラフィックを維持することが望ましいです。データセンターの予想される使用は、数千ノードが同様のことをやっている大規模なWebサーバファームとして機能することで、トラフィックパターンが大きくで、大規模データセンターの外にある、EORスイッチとアクセス層が使用される可能性がある場合それは複雑さを最小化するように、サーバおよびデータベースが同じL2ドメイン内に位置することを可能にし、最大密度を提供します。"
    },
    {
      "indent": 3,
      "text": "A data center that is expected to host a multi-tenant cloud hosting service might have some completely unique requirements. In order to isolate inter-customer traffic, smaller L2 domains might be preferred, and though the size of the overall data center might be comparable to the previous example, the multi-tenant nature of the cloud hosting application requires a smaller and more compartmentalized access layer. A multi-tenant environment might also require the use of L3 all the way to the access-layer ToR switch.",
      "ja": "マルチテナントクラウドホスティングサービスをホストするために期待されているデータセンターには、いくつかの完全に固有の要件があるかもしれません。インター顧客のトラフィックを分離するために、小さいL2ドメインは好ましいかもしれない、そして全体的なデータセンタの大きさは、前の例と同等であるかもしれないが、クラウドホスティングアプリケーションのマルチテナントの性質は、より小さく、より区画アクセスを必要とします層。マルチテナント環境では、すべての道アクセスレイヤのToRスイッチにL3を使用する必要があります。"
    },
    {
      "indent": 3,
      "text": "Yet another example of a workload with a unique traffic pattern is a high-performance compute cluster, where most of the traffic is expected to stay within the cluster but at the same time there is a high degree of crosstalk between the nodes. This would once again call for a large access layer in order to minimize the requirements at the aggregation layer.",
      "ja": "しかし、ユニークなトラフィックパターンを持つワークロードの別の例では、トラフィックのほとんどは、クラスタ内にとどまると予想される高性能計算クラスタ、であるが、同時に、ノード間のクロストーク度が高いです。これは、再びアグリゲーションレイヤでの要件を最小限にするために、大規模なアクセス層のために呼び出します。"
    },
    {
      "indent": 0,
      "text": "6.5.2. Virtualization",
      "section_title": true,
      "ja": "6.5.2. 仮想化"
    },
    {
      "indent": 3,
      "text": "Using virtualization in the data center further serves to increase the possible densities that can be achieved. However, virtualization also further complicates the requirements on the access layer, as virtualization restricts the scope of server placement in the event of server failover resulting from hardware failures or server migration for load balancing or other reasons.",
      "ja": "データセンター内の仮想化を使用してさらに達成することができる可能な密度を増加させるのに役立ちます。仮想化は、ロードバランシングまたは他の理由のために、ハードウェア障害やサーバの移行に起因するサーバフェイルオーバーの際にサーバーの配置の範囲を制限するようしかし、仮想化はまた、アクセス層上の要件を複雑にします。"
    },
    {
      "indent": 3,
      "text": "Virtualization also can place additional requirements on the aggregation switches in terms of address resolution table size and the scalability of any address-learning protocols that might be used on those switches. The use of virtualization often also requires the use of additional VLANs for high-availability beaconing, which would need to span the entire virtualized infrastructure. This would require the access layer to also span the entire virtualized infrastructure.",
      "ja": "仮想化はまた、アドレス解決テーブルのサイズとそれらのスイッチに使用されるかもしれない任意のアドレス学習プロトコルの拡張性の面で集約スイッチ上の追加要件を配置することができます。仮想化の利用は、多くの場合、また、全体の仮想化インフラストラクチャにまたがるする必要がある高可用性ビーコンのための追加のVLANを使用する必要があります。また、これは全体の仮想化インフラストラクチャにまたがるアクセス層を必要とします。"
    },
    {
      "indent": 0,
      "text": "6.5.3. Summary",
      "section_title": true,
      "ja": "6.5.3. 概要"
    },
    {
      "indent": 3,
      "text": "The designs described in this section have a number of tradeoffs. The \"L3 to access switches\" design described in Section 6.4.1 is the only design that constrains L2 domain size in a fashion that avoids ARP/ND scaling problems. However, that design has limitations and does not address some of the other requirements that lead to configurations that make use of larger L2 domains. Consequently, ARP/ND scaling issues are a real problem in practice.",
      "ja": "このセクションで説明するデザインはトレードオフの数を持っています。 6.4.1項で説明した「スイッチにアクセスするには、L3」のデザインは、ARP / NDスケーリングの問題を回避する方法でL2ドメインサイズを制約するだけなデザインです。しかし、そのデザインには限界があり、より大きなL2ドメインを利用する構成につながる他の要件のいくつかを解決しません。その結果、ARP / NDのスケーリングの問題は、実際には本当の問題です。"
    },
    {
      "indent": 0,
      "text": "7. Problem Itemization",
      "section_title": true,
      "ja": "7.問題箇条書き"
    },
    {
      "indent": 3,
      "text": "This section articulates some specific problems or \"pain points\" that are related to large data centers.",
      "ja": "このセクションでは、大規模なデータセンターに関連するいくつかの特定の問題や「痛みのポイント」を明確に表現します。"
    },
    {
      "indent": 0,
      "text": "7.1. ARP Processing on Routers",
      "section_title": true,
      "ja": "7.1. ルータのARPの処理"
    },
    {
      "indent": 3,
      "text": "One pain point with large L2 broadcast domains is that the routers connected to the L2 domain may need to process a significant amount of ARP traffic in some cases. In particular, environments where the aggregate level of ARP traffic is very large may lead to a heavy ARP load on routers. Even though the vast majority of ARP traffic may not be aimed at that router, the router still has to process enough of the ARP Request to determine whether it can safely be ignored. The ARP algorithm specifies that a recipient must update its ARP cache if it receives an ARP query from a source for which it has an entry [RFC0826].",
      "ja": "大きなL2ブロードキャストドメインを持つ一つの痛みのポイントはL2ドメインに接続されたルータは、いくつかのケースでARPトラフィックを大量に処理する必要があるかもしれないということです。具体的には、ARPトラフィックの集約レベルが非常に大きい環境では、ルータ上の重いARP負荷につながる可能性があります。 ARPトラフィックの大部分はそのルータを目的とされていない場合でも、ルータはまだそれを無視しても安全かどうかを判断するためにARP要求を十分に処理しなければなりません。 ARPアルゴリズムは、それがエントリー[RFC0826]を持っているソースからのARPクエリーを受信した場合、受信者はそのARPキャッシュを更新しなければならないことを指定します。"
    },
    {
      "indent": 3,
      "text": "ARP processing in routers is commonly handled in a \"slow path\" software processor, rather than directly by a hardware Application-Specific Integrated Circuit (ASIC) as is the case when forwarding packets. Such a design significantly limits the rate at which ARP traffic can be processed compared to the rate at which ASICs can forward traffic. Current implementations at the time of this writing can support ARP processing in the low thousands of ARP packets per second. In some deployments, limitations on the rate of ARP processing have been cited as being a problem.",
      "ja": "パケットを転送するときにそうであるようにルータ内のARP処理は、一般に、ハードウェアの特定用途向け集積回路（ASIC）によってではなく、直接より、「低速経路」ソフトウェア処理で処理されます。このような設計は大幅にARPトラフィックはASICはトラフィックを転送できる速度に比べて処理できる速度を制限します。この記事の執筆時点での現在の実装では、秒あたりのARPパケットの低い千ARP処理をサポートすることができます。いくつかの展開では、ARP処理速度に限界が問題点として指摘されています。"
    },
    {
      "indent": 3,
      "text": "To further reduce the ARP load, some routers have implemented additional optimizations in their forwarding ASIC paths. For example, some routers can be configured to discard ARP Requests for target addresses other than those assigned to the router. That way, the router's software processor only receives ARP Requests for addresses it owns and must respond to. This can significantly reduce the number of ARP Requests that must be processed by the router.",
      "ja": "さらにARPの負荷を軽減するために、いくつかのルータは、転送ASICパスに追加の最適化を実装しています。例えば、一部のルータは、ルータに割り当てられたもの以外のターゲット・アドレスに対するARP要求を破棄するように構成することができます。こうすることで、ルータのソフトウェアプロセッサは、それが所有しているアドレスに対してARP要求を受信して​​、に応答する必要があります。これはかなりのルータによって処理されなければならないARP要求の数を減らすことができます。"
    },
    {
      "indent": 3,
      "text": "Another optimization concerns reducing the number of ARP queries targeted at routers, whether for address resolution or to validate existing cache entries. Some routers can be configured to broadcast periodic gratuitous ARPs [RFC5227]. Upon receipt of a gratuitous ARP, implementations mark the associated entry as \"fresh\", resetting the aging timer to its maximum setting. Consequently, sending out periodic gratuitous ARPs can effectively prevent nodes from needing to send ARP Requests intended to revalidate stale entries for a router. The net result is an overall reduction in the number of ARP queries routers receive. Gratuitous ARPs, broadcast to all nodes in the L2 broadcast domain, may in some cases also pre-populate ARP caches on neighboring devices, further reducing ARP traffic. But it is not believed that pre-population of ARP entries is supported by most implementations, as the ARP specification [RFC0826] recommends only that pre-existing ARP entries be updated upon receipt of ARP messages; it does not call for the creation of new entries when none already exist.",
      "ja": "ルータを対象としたARPクエリの数を減らすもう一つの最適化の懸念、アドレス解決のために、または既存のキャッシュエントリを検証するかどうか。一部のルータは、定期的な無償のARP [RFC5227]をブロードキャストするように構成することができます。無償ARPを受信すると、実装はその最大設定にエージングタイマーをリセットし、「新鮮」として関連するエントリをマーク。そのため、定期的に無償ARPを送出することは効果的にルータの古いエントリを再検証することを目的とARP要求を送信する必要からノードを防ぐことができます。最終結果は、ARPの数の全体的な減少は、ルータが受信照会です。 L2ブロードキャストドメイン内のすべてのノードにブロードキャスト無償ARPが、いくつかのケースでも、事前に移入ARPはさらにARPトラフィックを削減、近隣のデバイスにキャッシュされますがあります。しかし、それだけで、既存のARPエントリがARPメッセージの受信時に更新されることをお勧めしますARP仕様[RFC0826]としてARPエントリの前人口は、ほとんどの実装によってサポートされているとは考えられません。どれもがすでに存在していないときには、新しいエントリを作成するために呼び出すことはありません。"
    },
    {
      "indent": 3,
      "text": "Finally, another area concerns the overhead of processing IP packets for which no ARP entry exists. Existing standards specify that one or more IP packets for which no ARP entries exist should be queued pending successful completion of the address resolution process [RFC1122] [RFC1812]. Once an ARP query has been resolved, any queued packets can be forwarded on. Again, the processing of such packets is handled in the \"slow path\", effectively limiting the rate at which a router can process ARP \"cache misses\", and is viewed as a problem in some deployments today. Additionally, if no response is received, the router may send the ARP/ND query multiple times. If no response is received after a number of ARP/ND requests, the router needs to drop any queued data packets and may send an ICMP destination unreachable message as well [RFC0792]. This entire process can be CPU intensive.",
      "ja": "最後に、他の領域にはARPエントリが存在しないための処理IPパケットのオーバーヘッドに関する。既存の標準にはARPエントリが存在しないための1つまたは複数のIPパケットは、アドレス解決処理が正常に完了した[RFC1122]、[RFC1812]ペンディングキューに入れなければならないことを指定します。 ARPクエリが解決されたら、任意のキューに入れられたパケットは、上に転送することができます。また、このようなパケットの処理を効果的に、ルータはARP「キャッシュ・ミス」を処理できる速度を制限し、「低速パス」で処理され、そして今日、いくつかの展開で問題視されています。応答がない場合はさらに、ルータはARP / NDクエリを複数回送信することがあります。応答がARP / ND要求の数の後に受信されない場合、ルータはいずれかをドロップする必要があるデータパケットをキューに入れられ、ICMP宛先到達不能メッセージも[RFC0792]を送信してもよいです。この全体のプロセスはCPUに負荷をかけすることができます。"
    },
    {
      "indent": 3,
      "text": "Although address resolution traffic remains local to one L2 network, some data center designs terminate L2 domains at individual aggregation switches/routers (e.g., see Section 6.4.2). Such routers can be connected to a large number of interfaces (e.g., 100 or more). While the address resolution traffic on any one interface may be manageable, the aggregate address resolution traffic across all interfaces can become problematic.",
      "ja": "アドレス解決トラフィック一のL2ネットワークへのローカルままであるが、一部のデータセンターは、（例えば、セクション6.4.2を参照）は、個々の集約スイッチ/ルータにL2ドメインを終了設計します。そのようなルータは、インターフェース（例えば、100以上）の大多数に接続することができます。いずれかのインターフェイス上のアドレス解決トラフィックを管理することができるが、すべてのインターフェイスを横切って集約アドレス解決トラフィックが問題になることができます。"
    },
    {
      "indent": 3,
      "text": "Another variant of the above issue has individual routers servicing a relatively small number of interfaces, with the individual interfaces themselves serving very large subnets. Once again, it is the aggregate quantity of ARP traffic seen across all of the router's interfaces that can be problematic. This pain point is essentially the same as the one discussed above, the only difference being whether a given number of hosts are spread across a few large IP subnets or many smaller ones.",
      "ja": "上記問題の別の変形は、個々のインターフェイス自体は、非常に大きなサブネットにサービスを提供して、インターフェースの比較的少数にサービスを提供する個々のルータを有しています。もう一度、それが問題になることがルータのインターフェイスのすべてにわたって見ARPトラフィックの集計量です。この痛みのポイントは、本質的に上述のものと同じであり、唯一の相違点ホストの所定の数が少ない大規模なIPサブネットまたは多くの小さいものに分散されているかどうかです。"
    },
    {
      "indent": 3,
      "text": "When hosts in two different subnets under the same L2/L3 boundary router need to communicate with each other, the L2/L3 router not only has to initiate ARP/ND requests to the target's subnet, it also has to process the ARP/ND requests from the originating subnet. This process further adds to the overall ARP processing load.",
      "ja": "同一のL2 / L3境界ルータ下に2つの異なるサブネット内のホストが相互に通信する必要がある場合、L2 / L3ルータだけでなく、ターゲットのサブネットにARP / ND要求を開始しなければならず、それはまた、ARP / ND要求を処理しなければなりません元のサブネットから。このプロセスは、さらに、全体のARP処理負荷に追加されます。"
    },
    {
      "indent": 0,
      "text": "7.2. IPv6 Neighbor Discovery",
      "section_title": true,
      "ja": "7.2.  IPv6近隣探索"
    },
    {
      "indent": 3,
      "text": "Though IPv6's Neighbor Discovery behaves much like ARP, there are several notable differences that result in a different set of potential issues. From an L2 perspective, an important difference is that ND address resolution requests are sent via multicast, which results in ND queries only being processed by the nodes for which they are intended. Compared with broadcast ARPs, this reduces the total number of ND packets that an implementation will receive.",
      "ja": "IPv6の近隣探索のは、多くのARPと同じように動作しますが、潜在的な問題の異なるセットにつながるいくつかの顕著な違いがあります。 L2の観点から、重要な違いは、NDのアドレス解決要求にのみ、それらが意図されているノードによって処理されるクエリNDもたらすマルチキャストを介して送信されることです。ブロードキャストのARPと比べて、これは実装が受け取るNDパケットの合計数を減少させます。"
    },
    {
      "indent": 3,
      "text": "Another key difference concerns revalidating stale ND entries. ND requires that nodes periodically revalidate any entries they are using, to ensure that bad entries are timed out quickly enough that TCP does not terminate a connection. Consequently, some implementations will send out \"probe\" ND queries to validate in-use ND entries as frequently as every 35 seconds [RFC4861]. Such probes are sent via unicast (unlike in the case of ARP). However, on larger networks, such probes can result in routers receiving many such queries (i.e., many more than with ARP, which does not specify such behavior). Unfortunately, the IPv4 mitigation technique of sending gratuitous ARPs (as described in Section 7.1) does not work in IPv6. The ND specification specifically states that gratuitous ND \"updates\" cannot cause an ND entry to be marked \"valid\". Rather, such entries are marked \"probe\", which causes the receiving node to (eventually) generate a probe back to the sender, which in this case is precisely the behavior that the router is trying to prevent!",
      "ja": "もう一つの重要な違いは、古いNDエントリを再検証に関するものです。 NDは、ノードが定期的に悪いエントリはTCPが接続を終了していないことを十分にすぐにタイムアウトしていることを保証するために、彼らが使用しているすべてのエントリを再検証する必要があります。その結果、いくつかの実装は、35秒ごとに[RFC4861]と同じ頻度で使用中のNDエントリを検証するために、「プローブ」NDクエリを送信します。そのようなプローブは、（ARPの場合とは異なり）ユニキャストを介して送信されます。しかし、大規模なネットワーク上で、そのようなプローブは、（そのような動作を指定していないARPとよりすなわち、より多くの）多くのこのようなクエリを受信するルータをもたらすことができます。残念ながら、（セクション7.1で説明したように）無償ARPを送信するIPv4の軽減技術は、IPv6では動作しません。 ND仕様は、特に無償ND「アップデート」はNDエントリが「有効」とマークさせることができないと述べています。受信ノードを起こしむしろ、そのようなエントリがマークされている「プローブ」、（最終的に）戻って、この場合には、正確にルータが予防しようとしている行動で、送信者へのプローブを生成！"
    },
    {
      "indent": 3,
      "text": "Routers implementing Neighbor Unreachability Discovery (NUD) (for neighboring destinations) will need to process neighbor cache state changes such as transitioning entries from REACHABLE to STALE. How this capability is implemented may impact the scalability of ND on a router. For example, one possible implementation is to have the forwarding operation detect when an ND entry is referenced that needs to transition from REACHABLE to STALE, by signaling an event that would need to be processed by the software processor. Such an implementation could increase the load on the service processor in much the same way that high rates of ARP requests have led to problems on some routers.",
      "ja": "（隣接地のための）近隣到達不能検出（NUD）を実装するルータは、このようなREACHABLEからSTALEにエントリを移行など近隣キャッシュ状態の変更を処理する必要があります。どのようにこの機能は、ルータ上でNDのスケーラビリティに影響を与える可能性が実装されています。例えば、一つの可能​​な実装は、NDエントリがソフトウェア処理によって処理される必要があるイベントをシグナリングすることによって、REACHABLEからSTALEに移行する必要があることで参照されたときに転送操作が検出させることです。このような実装は、ARP要求の高い率は一部のルータ上の問題につながっていることをほとんど同じように、サービスプロセッサの負荷が増加する可能性があります。"
    },
    {
      "indent": 3,
      "text": "It should be noted that ND does not require the sending of probes in all cases. Section 7.3.1 of [RFC4861] describes a technique whereby hints from TCP can be used to verify that an existing ND entry is working fine and does not need to be revalidated.",
      "ja": "NDがすべての場合に、プローブの送信を必要としないことに留意すべきです。 [RFC4861]のセクション7.3.1は、TCPからのヒントは、既存のNDエントリが正常に動作していると、再検証する必要がないことを確認するために使用することができる技術が記載されています。"
    },
    {
      "indent": 3,
      "text": "Finally, IPv6 and IPv4 are often run simultaneously and in parallel on the same network, i.e., in dual-stack mode. In such environments, the IPv4 and IPv6 issues enumerated above compound each other.",
      "ja": "最後に、IPv6とIPv4は、多くの場合、デュアルスタックモードで、即ち、同じネットワーク上で同時に並行して実行されます。そのような環境では、IPv4とIPv6の問題は、それぞれの他の化合物上に列挙しました。"
    },
    {
      "indent": 0,
      "text": "7.3. MAC Address Table Size Limitations in Switches",
      "section_title": true,
      "ja": "7.3. スイッチでMACアドレステーブルのサイズ制限"
    },
    {
      "indent": 3,
      "text": "L2 switches maintain L2 MAC address forwarding tables for all sources and destinations traversing the switch. These tables are populated through learning and are used to forward L2 frames to their correct destination. The larger the L2 domain, the larger the tables have to be. While in theory a switch only needs to keep track of addresses it is actively using (sometimes called \"conversational learning\"), switches flood broadcast frames (e.g., from ARP), multicast frames (e.g., from Neighbor Discovery), and unicast frames to unknown destinations. Switches add entries for the source addresses of such flooded frames to their forwarding tables. Consequently, MAC address table size can become a problem as the size of the L2 domain increases. The table size problem is made worse with VMs, where a single physical machine now hosts many VMs (in the 10's today, but growing rapidly as the number of cores per CPU increases), since each VM has its own MAC address that is visible to switches.",
      "ja": "L2スイッチは、スイッチを通過するすべてのソースと宛先のL2 MACアドレス転送テーブルを維持します。これらのテーブルは、学習によって移入され、その正しい宛先にL2フレームを転送するために使用されています。 L2ドメインより大きな、大きなテーブルがなければなりません。理論的には、スイッチが唯一それが積極的に（時には「会話学習」と呼ばれる）を使用しているアドレスを追跡する必要があるが、（ARPから例えば、）洪水ブロードキャストフレームを切り替えて（近隣探索から、例えば）、マルチキャストフレーム、およびユニキャストフレームへ宛先不明。スイッチは、その転送テーブルに、このような浸水フレームの送信元アドレスのエントリを追加します。その結果、MACアドレステーブルのサイズは、L2ドメインのサイズが大きくなるなどの問題となることができます。テーブルサイズの問題は、各VMは、それ自身のMACアドレスを有しているために表示される、単一の物理マシンは、現在、多くの仮想マシンをホストする仮想マシンで悪化し（10の今日ではなく、CPUが増加あたりのコアの数として急速に増加）されますスイッチ。"
    },
    {
      "indent": 3,
      "text": "When L3 extends all the way to access switches (see Section 6.4.1), the size of MAC address tables in switches is not generally a problem. When L3 extends only to aggregation switches (see Section 6.4.2), however, MAC table size limitations can be a real issue.",
      "ja": "L3は、スイッチ（セクション6.4.1を参照）にアクセスするためのすべての方法を拡張するときに、スイッチにMACアドレステーブルのサイズは、一般的に問題ではありません。 L3のみ集約スイッチ（セクション6.4.2を参照）まで延びている場合、しかし、MACテーブルのサイズの制限は、実際の問題であることができます。"
    },
    {
      "indent": 0,
      "text": "8. Summary",
      "section_title": true,
      "ja": "8.まとめ"
    },
    {
      "indent": 3,
      "text": "This document has outlined a number of issues related to address resolution in large data centers. In particular, this document has described different scenarios where such issues might arise and what these potential issues are, along with outlining fundamental factors that cause them. It is hoped that describing specific pain points will facilitate a discussion as to whether they should be addressed and how best to address them.",
      "ja": "このドキュメントでは、大規模なデータセンターでアドレス解決に関連する問題の数を概説しています。具体的には、この文書には、それらを引き起こす根本的な要因を概説とともに、そのような問題が発生する可能性があり、これらの潜在的な問題が何であるかの異なるシナリオを説明しました。彼らが対処すべきとどのように最高のそれらに対処するか否かの具体的な痛みのポイントを説明することは議論を促進することが期待されます。"
    },
    {
      "indent": 0,
      "text": "9. Acknowledgments",
      "section_title": true,
      "ja": "9.謝辞"
    },
    {
      "indent": 3,
      "text": "This document has been significantly improved by comments from Manav Bhatia, David Black, Stewart Bryant, Ralph Droms, Linda Dunbar, Donald Eastlake, Wesley Eddy, Anoop Ghanwani, Joel Halpern, Sue Hares, Pete Resnick, Benson Schliesser, T. Sridhar, and Lucy Yong. Igor Gashinsky deserves additional credit for highlighting some of the ARP-related pain points and for clarifying the difference between what the standards require and what some router vendors have actually implemented in response to operator requests.",
      "ja": "この文書では、大幅にManavバティア、デビッド・ブラック、スチュワートブライアント、ラルフDroms、リンダ・ダンバー、ドナルドイーストレイク、ウェズリーエディ、アヌープGhanwani、ジョエル・ハルパーン、スーノウサギ、ピート・レズニック、ベンソンSchliesser、T.シュリダール、およびからのコメントによって改善されましたルーシーヨンジュン。イゴールGashinskyはARP関連の痛みのいくつかの点を強調するために、どのような基準が必要とどのようないくつかのルータベンダーは、実際にオペレータの要求に応じて実施しているとの違いを明確にするため、追加の信用に値します。"
    },
    {
      "indent": 0,
      "text": "10. Security Considerations",
      "section_title": true,
      "ja": "10.セキュリティの考慮事項"
    },
    {
      "indent": 3,
      "text": "This document does not create any security implications nor does it have any security implications. The security vulnerabilities in ARP are well known, and this document does not change or mitigate them in any way. Security considerations for Neighbor Discovery are discussed in [RFC4861] and [RFC6583].",
      "ja": "このドキュメントは、セキュリティ上の問題を作成しておらず、どのようなセキュリティ上の意味を持っています。 ARPにおけるセキュリティの脆弱性はよく知られており、この文書は、どのような方法でそれらを変更したり、軽減しません。近隣探索のためのセキュリティ上の考慮事項は、[RFC4861]と[RFC6583]で議論されています。"
    },
    {
      "indent": 0,
      "text": "11. Informative References",
      "section_title": true,
      "ja": "11.参考文献"
    },
    {
      "indent": 3,
      "text": "[RFC0792] Postel, J., \"Internet Control Message Protocol\", STD 5, RFC 792, September 1981.",
      "ja": "[RFC0792]ポステル、J.、 \"インターネット制御メッセージプロトコル\"、STD 5、RFC 792、1981年9月。"
    },
    {
      "indent": 3,
      "text": "[RFC0826] Plummer, D., \"Ethernet Address Resolution Protocol: Or converting network protocol addresses to 48.bit Ethernet address for transmission on Ethernet hardware\", STD 37, RFC 826, November 1982.",
      "ja": "[RFC0826]プラマー、D.、「イーサネットアドレス解決プロトコル：またはイーサネットハードウェア上で送信するためのイーサネットアドレスを48ビットに、ネットワーク・プロトコル・アドレス変換」、STD 37、RFC 826、1982年11月。"
    },
    {
      "indent": 3,
      "text": "[RFC1122] Braden, R., \"Requirements for Internet Hosts - Communication Layers\", STD 3, RFC 1122, October 1989.",
      "ja": "[RFC1122]ブレーデン、R.、 \"インターネットホストのための要件 - 通信層\"、STD 3、RFC 1122、1989年10月。"
    },
    {
      "indent": 3,
      "text": "[RFC1812] Baker, F., \"Requirements for IP Version 4 Routers\", RFC 1812, June 1995.",
      "ja": "[RFC1812]ベイカー、F.、RFC 1812、1995年6月 \"IPバージョン4つのルータのための要件\"。"
    },
    {
      "indent": 3,
      "text": "[RFC4861] Narten, T., Nordmark, E., Simpson, W., and H. Soliman, \"Neighbor Discovery for IP version 6 (IPv6)\", RFC 4861, September 2007.",
      "ja": "[RFC4861] Narten氏、T.、Nordmarkと、E.、シンプソン、W.、およびH.ソリマン、 \"IPバージョン6（IPv6）のための近隣探索\"、RFC 4861、2007年9月。"
    },
    {
      "indent": 3,
      "text": "[RFC5227] Cheshire, S., \"IPv4 Address Conflict Detection\", RFC 5227, July 2008.",
      "ja": "[RFC5227]チェシャー、S.、 \"IPv4アドレス競合検出\"、RFC 5227、2008年7月。"
    },
    {
      "indent": 3,
      "text": "[RFC6583] Gashinsky, I., Jaeggli, J., and W. Kumari, \"Operational Neighbor Discovery Problems\", RFC 6583, March 2012.",
      "ja": "[RFC6583] Gashinsky、I.、Jaeggli、J.、およびW.クマリ、 \"オペレーショナル近隣探索問題\"、RFC 6583、2012年3月。"
    },
    {
      "indent": 0,
      "text": "Authors' Addresses",
      "ja": "著者のアドレス"
    },
    {
      "indent": 3,
      "text": "Thomas Narten IBM Corporation 3039 Cornwallis Ave. PO Box 12195 Research Triangle Park, NC 27709-2195 USA",
      "ja": "トーマスNarten氏IBMコーポレーション3039コーンウォリスアベニュー。私書箱12195リサーチトライアングルパーク、ノースカロライナ州27709から2195 USA"
    },
    {
      "indent": 3,
      "text": "EMail: narten@us.ibm.com",
      "ja": "メールアドレス：narten@us.ibm.com"
    },
    {
      "indent": 3,
      "text": "Manish Karir Merit Network Inc.",
      "ja": "マニッシュKhrirは、ネットワークインに値します。"
    },
    {
      "indent": 3,
      "text": "EMail: mkarir@merit.edu",
      "ja": "メールアドレス：mkarir@merit.edu"
    },
    {
      "indent": 3,
      "text": "Ian Foo Huawei Technologies",
      "ja": "イアン・フー華為技術"
    },
    {
      "indent": 3,
      "text": "EMail: Ian.Foo@huawei.com",
      "ja": "メールアドレス：Ian.Foo@huawei.com"
    }
  ]
}